###############################################
# Example .env file (copy to .env and edit)
# Only expose keys you actually use.
# The root docker-compose.yml reads these directly.
###############################################

## --- AI Provider Credentials (at least one required) --- ##
# If using OpenAI as primary
OPEN_AI_KEY=your_openai_api_key_here

# If using Gemini as primary or fallback
GEMINI_API_KEY=your_gemini_api_key_here

# Optional (future / supplementary)
AlphaAdvantage_API_KEY=your_alpha_vantage_api_key_here

## --- Provider Selection --- ##
# Valid values: openai | gemini
PRIMARY_AI_PROVIDER=openai
FALLBACK_AI_PROVIDER=gemini

## --- Model Configuration (override as needed) --- ##
OPENAI_CLASSIFICATION_MODEL=gpt-5-mini
OPENAI_RECOMMENDATION_MODEL=gpt-5-nano
GEMINI_CLASSIFICATION_MODEL=gemini-2.5-flash
GEMINI_RECOMMENDATION_MODEL=gemini-2.5-flash-lite

## --- Application Settings --- ##
MAX_STOCKS_DEFAULT=5

SECTORS="Technology,Consumer Cyclical,Industrials,Utilities,Healthcare,Communication,Energy,Consumer Defensive,Real Estate,Financial"

## --- Flask Runtime --- ##
FLASK_ENV=production
FLASK_DEBUG=0

## --- Frontend Build Flag --- ##
VITE_DOCKER_ENV=false

## --- Port Configuration --- ##
# Keep these in sync; compose maps them 1:1. Change if conflicts.
BACKEND_PORT=8881
FRONTEND_PORT=8173
# Used by backend/app.py and frontend/vite.config.ts (proxy target)

###############################################
# After editing:
#   ./start.sh            # local dev quick start
# or docker compose up    # containerized stack
###############################################